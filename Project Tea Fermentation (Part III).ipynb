{"cells":[{"cell_type":"markdown","metadata":{"id":"NCrUVbIJuGUq"},"source":["# Introduction\n","Hope you're reading this in <font color = 'orange'>Google Colab</font>.\n","\n","In Part II, we split our data into train/val/ and test. In this Part, we will train our deep learning model to classify tea fermentation levels.\n","\n","In this Part III, we will:\n","1. Build a CNN model \n","2. Train the model\n","3. Assess model performance\n","\n","Looks like a three-step process but it will be more.\n","\n","## Model building\n","With reference to the research paper, we will refer to this section frequently:\n","\n","![TeaNetSection](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectTeaFermentation/Section35TeaNetLabelled.png)\n","\n","These are the important bits:\n","1. Reference architecture (AlexNet)\n","2. Input image dimensions\n","3. Summary on the layers\n","4. Detailed definition of the layers\n","\n","### Step 1: Import libraries\n","We'll need quite a few libraries - in no particular order here they are:\n","1. numpy as np\n","2. ImageDataGenerator from keras.preprocessing.image\n","3. Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D from keras.layers\n","4. BatchNormalization from keras.layers.normalization\n","5. models, optimizers from keras\n","6. confusion_matrix from sklearn.metrics"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pE4G7vxDuViY","executionInfo":{"status":"ok","timestamp":1645150402973,"user_tz":-480,"elapsed":23277,"user":{"displayName":"mah peijun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGzWlc7csHjU9TYB1s0b51rmdix3PFnnBfjXAGcA=s64","userId":"12183156690255116761"}},"outputId":"c4da66e9-a00c-4bae-9b40-f85191a0b14b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":24,"metadata":{"id":"K_WcMGfguGUs","executionInfo":{"status":"ok","timestamp":1645155113779,"user_tz":-480,"elapsed":1658,"user":{"displayName":"mah peijun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGzWlc7csHjU9TYB1s0b51rmdix3PFnnBfjXAGcA=s64","userId":"12183156690255116761"}}},"outputs":[],"source":["# Step 1: Import libraries\n","import numpy as np\n","import tensorflow as tf\n","import keras\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n","from tensorflow.keras.layers import BatchNormalization\n","from keras import models, optimizers \n","from sklearn.metrics import confusion_matrix\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"88_dAsVXuGUt"},"source":["### Step 2: Implement the original AlexNet first\n","As mentioned, TeaNet is based on the AlexNet architecture. \n","\n","To make your time building TeaNet easier, why not start from AlexNet and then start modifying? \n","\n","Very useful resource if you don't know how to create your CNN layers from scratch: https://analyticsindiamag.com/hands-on-guide-to-implementing-alexnet-with-keras-for-multi-class-image-classification/\n","\n","You can even copy the code wholesale first, including comments. You just need the middle portion of the article, and you can stop right after compiling the model.\n","\n","If you're not sure where to start in the article, start with:\n","```\n","AlexNet = models.Sequential()\n","```\n","and end at \n","```\n","AlexNet.compile(loss = keras.losses.categorical_crossentropy, optimizer= 'adam', metrics=['accuracy'])\n","```\n","\n","When you get the model summary, make sure the 'Param #' values match and you're all good. "]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PX1aBT93uGUt","executionInfo":{"status":"ok","timestamp":1645150406996,"user_tz":-480,"elapsed":49,"user":{"displayName":"mah peijun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGzWlc7csHjU9TYB1s0b51rmdix3PFnnBfjXAGcA=s64","userId":"12183156690255116761"}},"outputId":"305d4896-53f9-49a0-8d07-3522caa93214"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 8, 8, 96)          34944     \n","                                                                 \n"," batch_normalization (BatchN  (None, 8, 8, 96)         384       \n"," ormalization)                                                   \n","                                                                 \n"," activation (Activation)     (None, 8, 8, 96)          0         \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 4, 4, 96)         0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 4, 4, 256)         614656    \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 4, 4, 256)        1024      \n"," hNormalization)                                                 \n","                                                                 \n"," activation_1 (Activation)   (None, 4, 4, 256)         0         \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 2, 2, 256)        0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 2, 2, 384)         885120    \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 2, 2, 384)        1536      \n"," hNormalization)                                                 \n","                                                                 \n"," activation_2 (Activation)   (None, 2, 2, 384)         0         \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 2, 2, 384)         1327488   \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 2, 2, 384)        1536      \n"," hNormalization)                                                 \n","                                                                 \n"," activation_3 (Activation)   (None, 2, 2, 384)         0         \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 2, 2, 256)         884992    \n","                                                                 \n"," batch_normalization_4 (Batc  (None, 2, 2, 256)        1024      \n"," hNormalization)                                                 \n","                                                                 \n"," activation_4 (Activation)   (None, 2, 2, 256)         0         \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 1, 1, 256)        0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 256)               0         \n","                                                                 \n"," dense (Dense)               (None, 4096)              1052672   \n","                                                                 \n"," batch_normalization_5 (Batc  (None, 4096)             16384     \n"," hNormalization)                                                 \n","                                                                 \n"," activation_5 (Activation)   (None, 4096)              0         \n","                                                                 \n"," dropout (Dropout)           (None, 4096)              0         \n","                                                                 \n"," dense_1 (Dense)             (None, 4096)              16781312  \n","                                                                 \n"," batch_normalization_6 (Batc  (None, 4096)             16384     \n"," hNormalization)                                                 \n","                                                                 \n"," activation_6 (Activation)   (None, 4096)              0         \n","                                                                 \n"," dropout_1 (Dropout)         (None, 4096)              0         \n","                                                                 \n"," dense_2 (Dense)             (None, 1000)              4097000   \n","                                                                 \n"," batch_normalization_7 (Batc  (None, 1000)             4000      \n"," hNormalization)                                                 \n","                                                                 \n"," activation_7 (Activation)   (None, 1000)              0         \n","                                                                 \n"," dropout_2 (Dropout)         (None, 1000)              0         \n","                                                                 \n"," dense_3 (Dense)             (None, 10)                10010     \n","                                                                 \n"," batch_normalization_8 (Batc  (None, 10)               40        \n"," hNormalization)                                                 \n","                                                                 \n"," activation_8 (Activation)   (None, 10)                0         \n","                                                                 \n","=================================================================\n","Total params: 25,730,506\n","Trainable params: 25,709,350\n","Non-trainable params: 21,156\n","_________________________________________________________________\n"]}],"source":["# Step 2: Implement the original AlexNet\n","np.random.seed(1000)\n","\n","#Instantiation\n","AlexNet = Sequential()\n","\n","#1st Convolutional Layer\n","AlexNet.add(Conv2D(filters=96, input_shape=(32,32,3), kernel_size=(11,11), strides=(4,4), padding='same'))\n","AlexNet.add(BatchNormalization())\n","AlexNet.add(Activation('relu'))\n","AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n","\n","#2nd Convolutional Layer\n","AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\n","AlexNet.add(BatchNormalization())\n","AlexNet.add(Activation('relu'))\n","AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n","\n","#3rd Convolutional Layer\n","AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n","AlexNet.add(BatchNormalization())\n","AlexNet.add(Activation('relu'))\n","\n","#4th Convolutional Layer\n","AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n","AlexNet.add(BatchNormalization())\n","AlexNet.add(Activation('relu'))\n","\n","#5th Convolutional Layer\n","AlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n","AlexNet.add(BatchNormalization())\n","AlexNet.add(Activation('relu'))\n","AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n","\n","#Passing it to a Fully Connected layer\n","AlexNet.add(Flatten())\n","# 1st Fully Connected Layer\n","AlexNet.add(Dense(4096, input_shape=(32,32,3,)))\n","AlexNet.add(BatchNormalization())\n","AlexNet.add(Activation('relu'))\n","# Add Dropout to prevent overfitting\n","AlexNet.add(Dropout(0.4))\n","\n","#2nd Fully Connected Layer\n","AlexNet.add(Dense(4096))\n","AlexNet.add(BatchNormalization())\n","AlexNet.add(Activation('relu'))\n","#Add Dropout\n","AlexNet.add(Dropout(0.4))\n","\n","#3rd Fully Connected Layer\n","AlexNet.add(Dense(1000))\n","AlexNet.add(BatchNormalization())\n","AlexNet.add(Activation('relu'))\n","#Add Dropout\n","AlexNet.add(Dropout(0.4))\n","\n","#Output Layer\n","AlexNet.add(Dense(10))\n","AlexNet.add(BatchNormalization())\n","AlexNet.add(Activation('softmax'))\n","\n","#Model Summary\n","AlexNet.summary()"]},{"cell_type":"markdown","metadata":{"id":"NGNckIBluGUu"},"source":["### Step 3: Modify AlexNet and turn it into TeaNet\n","Now that you've successfully implemented AlexNet, time to modify the parameters according to the publication. \n","\n","We'll tweak it to ask close as it's needed to TeaNet (plus a bit of our own modification):\n","\n","<strong>More specifically, to turn AlexNet into TeaNet, you will need to:</strong>\n","1. Change the input_shape parameter in first layer\n","2. Change the filter sizes in each layer to match the publication\n","3. Remove 'padding' parameter in all layers\n","4. Change the drop out ratio\n","5. Completely remove the # Output Layer\n","6. In the 3rd fully connected layer:\n","    - Change the number of neurons in the third fully connected layer from 1000 to 3\n","    - Change the activation from 'relu' to 'softmax'\n","    - Remove the dropout operation\n","7. Change the compile parameters\n","    - Change the optimizer from adam to optimizers.SGD with a learning rate of 0.01, and momentum of 0.9\n","    \n","At the model summary, see if your parameters look like this:\n","```\n","Total params: 239,567\n","Trainable params: 237,833\n","Non-trainable params: 1,734\n","```\n","\n","You're on the right track."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_B1YLvT6uGUu","executionInfo":{"status":"ok","timestamp":1645150406996,"user_tz":-480,"elapsed":25,"user":{"displayName":"mah peijun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGzWlc7csHjU9TYB1s0b51rmdix3PFnnBfjXAGcA=s64","userId":"12183156690255116761"}},"outputId":"77775787-3e36-4b3d-b0ef-ea76394bb2e0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_5 (Conv2D)           (None, 35, 35, 32)        11648     \n","                                                                 \n"," batch_normalization_9 (Batc  (None, 35, 35, 32)       128       \n"," hNormalization)                                                 \n","                                                                 \n"," activation_9 (Activation)   (None, 35, 35, 32)        0         \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 17, 17, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 8, 8, 64)          18496     \n","                                                                 \n"," batch_normalization_10 (Bat  (None, 8, 8, 64)         256       \n"," chNormalization)                                                \n","                                                                 \n"," activation_10 (Activation)  (None, 8, 8, 64)          0         \n","                                                                 \n"," max_pooling2d_4 (MaxPooling  (None, 4, 4, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 1, 1, 128)         73856     \n","                                                                 \n"," batch_normalization_11 (Bat  (None, 1, 1, 128)        512       \n"," chNormalization)                                                \n","                                                                 \n"," activation_11 (Activation)  (None, 1, 1, 128)         0         \n","                                                                 \n"," flatten_1 (Flatten)         (None, 128)               0         \n","                                                                 \n"," dense_4 (Dense)             (None, 512)               66048     \n","                                                                 \n"," batch_normalization_12 (Bat  (None, 512)              2048      \n"," chNormalization)                                                \n","                                                                 \n"," activation_12 (Activation)  (None, 512)               0         \n","                                                                 \n"," dropout_3 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_5 (Dense)             (None, 128)               65664     \n","                                                                 \n"," batch_normalization_13 (Bat  (None, 128)              512       \n"," chNormalization)                                                \n","                                                                 \n"," activation_13 (Activation)  (None, 128)               0         \n","                                                                 \n"," dropout_4 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_6 (Dense)             (None, 3)                 387       \n","                                                                 \n"," batch_normalization_14 (Bat  (None, 3)                12        \n"," chNormalization)                                                \n","                                                                 \n"," activation_14 (Activation)  (None, 3)                 0         \n","                                                                 \n","=================================================================\n","Total params: 239,567\n","Trainable params: 237,833\n","Non-trainable params: 1,734\n","_________________________________________________________________\n"]}],"source":["# Step 3: Modify AlexNet to TeaNet\n","# Step 2: Implement the original AlexNet\n","np.random.seed(1000)\n","\n","#Instantiation\n","TeaNet = Sequential()\n","\n","#1st Convolutional Layer\n","TeaNet.add(Conv2D(filters=32, input_shape=(150,150,3), kernel_size=(11,11), strides=(4,4)))\n","TeaNet.add(BatchNormalization())\n","TeaNet.add(Activation('relu'))\n","TeaNet.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n","\n","#2nd Convolutional Layer\n","TeaNet.add(Conv2D(filters=64, kernel_size=(3, 3), strides=(2,2)))\n","TeaNet.add(BatchNormalization())\n","TeaNet.add(Activation('relu'))\n","TeaNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n","\n","#3rd Convolutional Layer\n","TeaNet.add(Conv2D(filters=128, kernel_size=(3,3), strides=(2,2)))\n","TeaNet.add(BatchNormalization())\n","TeaNet.add(Activation('relu'))\n","\n","\n","#Passing it to a Fully Connected layer\n","TeaNet.add(Flatten())\n","# 1st Fully Connected Layer\n","TeaNet.add(Dense(512))\n","TeaNet.add(BatchNormalization())\n","TeaNet.add(Activation('relu'))\n","# Add Dropout to prevent overfitting\n","TeaNet.add(Dropout(0.5))\n","\n","#2nd Fully Connected Layer\n","TeaNet.add(Dense(128))\n","TeaNet.add(BatchNormalization())\n","TeaNet.add(Activation('relu'))\n","#Add Dropout\n","TeaNet.add(Dropout(0.5))\n","\n","#3rd Fully Connected Layer\n","TeaNet.add(Dense(3))\n","TeaNet.add(BatchNormalization())\n","TeaNet.add(Activation('softmax'))\n","\n","\n","#Model Summary\n","TeaNet.summary()"]},{"cell_type":"code","source":["TeaNet.compile(loss = keras.losses.categorical_crossentropy, optimizer= tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9), metrics=['accuracy'])"],"metadata":{"id":"3by8Ati6tDLx","executionInfo":{"status":"ok","timestamp":1645150409217,"user_tz":-480,"elapsed":492,"user":{"displayName":"mah peijun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGzWlc7csHjU9TYB1s0b51rmdix3PFnnBfjXAGcA=s64","userId":"12183156690255116761"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nL9OtA3vuGUv"},"source":["## Preparing your images\n","We haven't set our training, validation, and test data yet so we can't train. \n","\n","### Step 4: Define the classes\n","Declare a variable, and assign it with a dictionary with the following key-value pair:\n","1. 'underfermented tea' - 0\n","2. 'overfermented tea' - 1\n","3. 'fermented tea' - 2\n","\n","The reason why we do this is that sometimes model training on Keras can lead the classes being mixed up. As such, it's better to explicitly declare what our classes and its corresponding values are. "]},{"cell_type":"code","execution_count":6,"metadata":{"id":"3TQZkgleuGUv","executionInfo":{"status":"ok","timestamp":1645150410583,"user_tz":-480,"elapsed":2,"user":{"displayName":"mah peijun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGzWlc7csHjU9TYB1s0b51rmdix3PFnnBfjXAGcA=s64","userId":"12183156690255116761"}}},"outputs":[],"source":["# Step 4: Declare your classes\n","TeaClass = {'underfermented tea':0, 'overfermented tea':1, 'fermented tea':2}"]},{"cell_type":"markdown","metadata":{"id":"b40G5vPsuGUw"},"source":["### Step 5: Create ImageDataGenerator objects\n","We will be generating batches of augmented image data during model training, so we will be creating ImageDataGenerator objects. \n","\n","Handy reading: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n","\n","Declare three variables, and assign them ImageDataGenerator objects with the following parameters\n","1. train generator\n","    - rescale - 1.0/255\n","    - shear_range - 0.2\n","    - zoom_range - 0.2\n","    - horizontal_flip - True\n","2. test generator\n","    - rescale - 1.0/255\n","3. val generator\n","    - rescale - 1.0/255"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"A8gTFLpmuGUw","executionInfo":{"status":"ok","timestamp":1645150414349,"user_tz":-480,"elapsed":335,"user":{"displayName":"mah peijun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGzWlc7csHjU9TYB1s0b51rmdix3PFnnBfjXAGcA=s64","userId":"12183156690255116761"}}},"outputs":[],"source":["# Step 5: Create your three ImageDataGenerator objects\n","train_generator=ImageDataGenerator(rescale=1/255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n","test_generator=ImageDataGenerator(rescale=1/255)\n","val_generator=ImageDataGenerator(rescale=1/255)"]},{"cell_type":"markdown","metadata":{"id":"rKHNNr98uGUw"},"source":["### Step 6: Declare your train/val/test folder paths\n","Declare three variables, and assign them the path to your train, val, and test folders. \n","\n","Navigate to the folders that you got from Part II Step 6, and copy the path."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"QczX422kuGUx","executionInfo":{"status":"ok","timestamp":1645150417059,"user_tz":-480,"elapsed":343,"user":{"displayName":"mah peijun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGzWlc7csHjU9TYB1s0b51rmdix3PFnnBfjXAGcA=s64","userId":"12183156690255116761"}}},"outputs":[],"source":["# Step 6: Store the path to variables\n","train_path='/content/drive/MyDrive/Project Tea Fermentation/Black tea fermentation dataset/output/train'\n","test_path='/content/drive/MyDrive/Project Tea Fermentation/Black tea fermentation dataset/output/test'\n","val_path='/content/drive/MyDrive/Project Tea Fermentation/Black tea fermentation dataset/output/val'"]},{"cell_type":"markdown","metadata":{"id":"t8MFs2XMuGUx"},"source":["### Step 7: Declare your train/validation/test .flow_from_directory\n","Next up, we will declare three new variables, and in each variable you use the .flow_from_directory method from your ImageDataGenerators that you created in Step 5. \n","\n","Here are the parameters to use:\n","1. train set\n","    - path - the path you declared from Step 6\n","    - target_size - (150, 150)\n","    - batch_size - 16\n","    - class_mode - 'categorical'\n","    - classes - the dictonary from Step 4\n","2. test set\n","    - same as train generator\n","    - shuffle - False\n","3. val set\n","    - same as train generator\n","    - shuffle - False\n","\n","If your folder structure is correct, split your files properly, and declare the right paths, you'll see this:\n","\n","![FlowFromDirectoryResults](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectTeaFermentation/FlowFromDirectoryOutput.png)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Oq07tXquGUx","executionInfo":{"status":"ok","timestamp":1645150451067,"user_tz":-480,"elapsed":31005,"user":{"displayName":"mah peijun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGzWlc7csHjU9TYB1s0b51rmdix3PFnnBfjXAGcA=s64","userId":"12183156690255116761"}},"outputId":"079b9e76-8ca3-4eaf-ddba-dd6a05ca1673"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 4800 images belonging to 3 classes.\n","Found 600 images belonging to 3 classes.\n","Found 600 images belonging to 3 classes.\n"]}],"source":["# Step 7: Declare your .flow_from_directory variables\n","train_generator=train_generator.flow_from_directory(train_path, target_size=(150, 150), batch_size=16, class_mode='categorical', classes=TeaClass)\n","test_generator=test_generator.flow_from_directory(test_path, target_size=(150, 150), batch_size=16, class_mode='categorical', classes=TeaClass, shuffle=False)\n","val_generator=val_generator.flow_from_directory(val_path, target_size=(150, 150), batch_size=16, class_mode='categorical', classes=TeaClass, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"2zYut977uGUy"},"source":["## Model training and assessment\n","### Step 8: Train your CNN\n","Now that everything is set up, we can now train our model. \n","\n","Declare a variable called history, and assign it to your model's .fit() method with the following parameters:\n","1. train_set - train set from Step 7\n","2. steps_per_epoch - 20\n","3. epochs - 20\n","4. verbose - 1\n","5. validation_set - val set from Step 7\n","\n","If everything works, you'll see something like this:\n","\n","![TrainOutput](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectTeaFermentation/TrainOutput.png)\n","\n","Be patient and revisit Steps 2-3 if it doesn't work. You should have\n","1. low acc_loss\n","2. low val_loss\n","3. high acc\n","4. high val_acc"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F8E3ZxF0uGUy","executionInfo":{"status":"ok","timestamp":1645151711694,"user_tz":-480,"elapsed":1259553,"user":{"displayName":"mah peijun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGzWlc7csHjU9TYB1s0b51rmdix3PFnnBfjXAGcA=s64","userId":"12183156690255116761"}},"outputId":"32ea78a8-11a1-441b-ca68-b8308df0814d"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  \n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","20/20 [==============================] - 273s 14s/step - loss: 0.7321 - accuracy: 0.7437 - val_loss: 11.2665 - val_accuracy: 0.3333\n","Epoch 2/20\n","20/20 [==============================] - 65s 3s/step - loss: 0.2898 - accuracy: 0.9875 - val_loss: 9.3618 - val_accuracy: 0.3333\n","Epoch 3/20\n","20/20 [==============================] - 65s 3s/step - loss: 0.2423 - accuracy: 0.9812 - val_loss: 5.3072 - val_accuracy: 0.3333\n","Epoch 4/20\n","20/20 [==============================] - 60s 3s/step - loss: 0.1645 - accuracy: 1.0000 - val_loss: 3.5794 - val_accuracy: 0.3333\n","Epoch 5/20\n","20/20 [==============================] - 53s 3s/step - loss: 0.1216 - accuracy: 1.0000 - val_loss: 2.1074 - val_accuracy: 0.3333\n","Epoch 6/20\n","20/20 [==============================] - 49s 2s/step - loss: 0.1281 - accuracy: 0.9906 - val_loss: 1.1295 - val_accuracy: 0.3333\n","Epoch 7/20\n","20/20 [==============================] - 49s 2s/step - loss: 0.1108 - accuracy: 0.9906 - val_loss: 0.9384 - val_accuracy: 0.3333\n","Epoch 8/20\n","20/20 [==============================] - 44s 2s/step - loss: 0.0790 - accuracy: 1.0000 - val_loss: 0.4202 - val_accuracy: 1.0000\n","Epoch 9/20\n","20/20 [==============================] - 43s 2s/step - loss: 0.0654 - accuracy: 1.0000 - val_loss: 0.4000 - val_accuracy: 0.6667\n","Epoch 10/20\n","20/20 [==============================] - 41s 2s/step - loss: 0.0792 - accuracy: 0.9937 - val_loss: 0.1179 - val_accuracy: 1.0000\n","Epoch 11/20\n","20/20 [==============================] - 35s 2s/step - loss: 0.0619 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 1.0000\n","Epoch 12/20\n","20/20 [==============================] - 37s 2s/step - loss: 0.0573 - accuracy: 1.0000 - val_loss: 0.0575 - val_accuracy: 1.0000\n","Epoch 13/20\n","20/20 [==============================] - 33s 2s/step - loss: 0.0508 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 1.0000\n","Epoch 14/20\n","20/20 [==============================] - 29s 1s/step - loss: 0.0883 - accuracy: 0.9875 - val_loss: 0.2659 - val_accuracy: 1.0000\n","Epoch 15/20\n","20/20 [==============================] - 32s 2s/step - loss: 0.0629 - accuracy: 0.9969 - val_loss: 0.1733 - val_accuracy: 1.0000\n","Epoch 16/20\n","20/20 [==============================] - 32s 2s/step - loss: 0.0419 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 1.0000\n","Epoch 17/20\n","20/20 [==============================] - 23s 1s/step - loss: 0.0490 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 1.0000\n","Epoch 18/20\n","20/20 [==============================] - 24s 1s/step - loss: 0.0855 - accuracy: 0.9875 - val_loss: 0.2028 - val_accuracy: 1.0000\n","Epoch 19/20\n","20/20 [==============================] - 25s 1s/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.0358 - val_accuracy: 1.0000\n","Epoch 20/20\n","20/20 [==============================] - 22s 1s/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.0289 - val_accuracy: 1.0000\n"]}],"source":["# Step 8: Train your model\n","hisotry=TeaNet.fit_generator(train_generator, steps_per_epoch = 20, epochs = 20, verbose=1, validation_data = val_generator)"]},{"cell_type":"markdown","metadata":{"id":"QEmjvxQ9uGUy"},"source":["### Step 9: Make predictions using test set\n","After we're done training, you will notice that both accuracy and validation accuracy is high. How does it fare against the test set? \n","\n","Use the .predict method of your CNN model and use the test set variable that you declared in Step 7 to make your predictions.\n","\n","You should see something like this: \n","\n","![TestSetPrediction](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectTeaFermentation/PredictionFromTestSet.png)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FlyfdB7puGUy","executionInfo":{"status":"ok","timestamp":1645153676032,"user_tz":-480,"elapsed":179042,"user":{"displayName":"mah peijun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGzWlc7csHjU9TYB1s0b51rmdix3PFnnBfjXAGcA=s64","userId":"12183156690255116761"}},"outputId":"0ad2aeee-9a60-449a-f7c3-eae0179643dc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.9792427 , 0.01025292, 0.01050442],\n","       [0.9781597 , 0.0113948 , 0.01044545],\n","       [0.9792427 , 0.01025292, 0.01050442],\n","       ...,\n","       [0.02547402, 0.02206491, 0.9524611 ],\n","       [0.02547404, 0.02206493, 0.952461  ],\n","       [0.01765895, 0.01643343, 0.9659076 ]], dtype=float32)"]},"metadata":{},"execution_count":12}],"source":["# Step 9: Make predictions using your test set\n","y_pred=TeaNet.predict(test_generator)\n","y_pred"]},{"cell_type":"markdown","metadata":{"id":"BJNIerHTuGUz"},"source":["### Step 10: Get the index of maximum value in each prediction array\n","If you've noticed, each item in the list of prediction is another list containing the probabilities of each class. \n","\n","Use numpy's argmax method to get the index of the highest value in the array - that is your class prediction.\n","\n","<strong>Hint: Google \"How to find the predicted class for a specific testing sample\"</strong>"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Va6EmGrvuGUz","executionInfo":{"status":"ok","timestamp":1645154523875,"user_tz":-480,"elapsed":573,"user":{"displayName":"mah peijun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGzWlc7csHjU9TYB1s0b51rmdix3PFnnBfjXAGcA=s64","userId":"12183156690255116761"}},"outputId":"5b27e9af-6cc7-45fc-92d9-d42365b7c7a9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","       2, 2, 2, 2, 2, 2])"]},"metadata":{},"execution_count":14}],"source":["# Step 10: Get the index of the max value in each prediction array\n","y_pred_cat=np.argmax(y_pred,axis=1)\n","y_pred_cat"]},{"cell_type":"markdown","metadata":{"id":"gYp3LtxnuGUz"},"source":["### Step 11: Assess your prediction with a confusion matrix\n","Earlier on, you imported confusion_matrix from sklearn.metrics. \n","\n","Now's the time to use it, as you get the .classes attribute from your test set from Step 7, and compare it with the predictions you got from Step 10."]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BdzQe4Y-uGUz","executionInfo":{"status":"ok","timestamp":1645154928124,"user_tz":-480,"elapsed":357,"user":{"displayName":"mah peijun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGzWlc7csHjU9TYB1s0b51rmdix3PFnnBfjXAGcA=s64","userId":"12183156690255116761"}},"outputId":"a1b3b88d-001f-4d53-ffc7-1b22a83bc486"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[200,   0,   0],\n","       [  0, 200,   0],\n","       [  0,   0, 200]])"]},"metadata":{},"execution_count":22}],"source":["# Step 11: Print a confusion matrix\n","y_true=test_generator.classes\n","confusion_matrix(y_true,y_pred_cat)"]},{"cell_type":"markdown","metadata":{"id":"eHc2EXJQuGU0"},"source":["### Step 12: Plot your accuracy and loss\n","Wait a minute - the results from Step 11 seems too good. What's wrong, and are we overfitting?\n","\n","Judging from the fact that we used a test set that was completely separate from train set and validation set, we can say that our results are great. \n","\n","Nonetheless, let's plot graphs:\n","1. accuracy vs epoch\n","2. loss vs epoch\n","\n","And in each graph we compare the changes over time for both train and val over the epochs.\n","\n","To retrieve the information you need, you can use the .history attribute from the 'history' variable that you declared in Step 8.\n","\n","![TrainValAccuracyLoss](https://uplevelsg.s3-ap-southeast-1.amazonaws.com/ProjectTeaFermentation/TrainValAccuracyLossPlot.png)\n","\n","You'll see something like this.\n","\n","<strong>Hint: Google \"keras plot training, validation and test set accuracy\"</strong>"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"0oj-45enuGU0","executionInfo":{"status":"ok","timestamp":1645155168223,"user_tz":-480,"elapsed":935,"user":{"displayName":"mah peijun","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiGzWlc7csHjU9TYB1s0b51rmdix3PFnnBfjXAGcA=s64","userId":"12183156690255116761"}},"outputId":"03f9aff0-b6b0-4090-b8b5-0dd67aa535a3"},"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["# Step 12: Plot your accuracy and val plots\n","#Plotting the training accuracy and validation accuracy\n","plt.plot(hisotry.history['accuracy'],color='b',label='Training  Accuracy')\n","plt.plot(hisotry.history['val_accuracy'],color='r',label='Validation Accuracy')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"KZX_DVvluGU0"},"source":["### End of Part III\n","That was long, wasn't it? But based on the results from Step 11 and Step 12, we would say it's well worth it. \n","\n","If you carried everything out well so far, congratulations! \n","\n","You're theoretically supposed to train a model that can predict 100% the state of fermentation of the leave based on image data alone. \n","\n","If you haven't, it's a good time to go back and revisit steps that you might have executed wrongly. \n","\n","Otherwise, let's head on to Parts IV and V where we will take a step back and return to our machine learning roots."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"Project Tea Fermentation (Part III).ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}